## 一、Redis并发问题

首先需要澄清一个事实：redis服务端是单线程处理客户端请求，也就是说客户端请求在服务端是串行化执行的，因此对服务端来说，并不存在并发问题。但业务方却存在并发操作redis中的同一个key的情况。所以如何让A客户端知道B客户端正在操作它想操作的 key，就成了必须要讨论的问题。


Redis为单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，但是在Jedis客户端对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题，这些问题均是由于客户端连接混乱造成。对此有2种解决方法：

1. Jedis是一个Java语言的Redis客户端，它为Java语言连接与操作Redis提供了简单易用的接口。Jedis不是线程安全的，故不应该在多线程环境中共用一个Jedis实例。但是，也应该避免直接创建多个Jedis实例，因为这种做法会导致创建过多的socket连接，性能不高。

客户端角度，为保证每个客户端间正常有序与Redis进行通信，对连接进行池化，同时对客户端读写Redis操作采用内部锁synchronized。要保证线程安全且获得较好的性能，可以使用JedisPool。JedisPool是一个连接池，既可以保证线程安全，又可以保证了较高的效率。

2. 服务器角度，利用setnx实现锁。语法：SETNX key value

## 二、Redis高并发的问题

Redis缓存的高性能有目共睹，应用的场景也是非常广泛，但是在高并发的场景下，也会出现问题：缓存击穿、缓存雪崩、缓存和数据一致性，以及今天要谈到的缓存并发竞争。这里的并发指的是多个redis的client同时set key引起的并发问题，不是事务，多个事件并发。

### 2.1、出现并发设置Key的原因

Redis是一种单线程机制的nosql数据库，基于key-value，数据可持久化落盘。由于单线程所以Redis本身并没有锁的概念，多个客户端连接并不存在竞争关系，但是利用jedis等客户端对Redis进行并发访问时会出现问题。

比如：同时有多个子系统去set一个key。这个时候要注意什么呢？

### 2.3、举例

考虑到redis没有像db中的sql语句，update val = val + 10 where ...，无法使用这种方式进行对数据的更新。假如有某个key = "price"，value值为10，现在想把value值进行+10操作。正常逻辑下，就是先把数据key为price的值读回来，加上10，再把值给设置回去。如果只有一个连接的情况下，这种方式没有问题，可以工作得很好，但如果有两个连接时，两个连接同时想对还price进行+10操作，就可能会出现问题了。

例如：两个连接同时对price进行写操作，同时加10，最终结果我们知道，应该为30才是正确。考虑到一种情况：

>T1时刻，连接1将price读出，目标设置的数据为10+10 = 20。

>T2时刻，连接2也将数据读出，也是为10，目标设置为20。

>T3时刻，连接1将price设置为20。

>T4时刻，连接2也将price设置为20，则最终结果是一个错误值20。


如何解决redis的并发竞争key问题呢？下面给到2个Redis并发竞争的解决方案。


## 三、解决办法

### 3.1、分布式锁+时间戳

1.整体技术方案

这种情况，主要是准备一个分布式锁，大家去抢锁，抢到锁就做set操作。加锁的目的实际上就是把并行读写改成串行读写的方式，从而来避免资源竞争。

2.Redis分布式锁的实现

主要用到的redis函数是setnx()，用SETNX实现分布式锁。

利用SETNX非常简单地实现分布式锁。例如：某客户端要获得一个名字youzhi的锁，客户端使用下面的命令进行获取：

>SETNX lock.youzhi<current Unix time + lock timeout + 1>

如返回1，则该客户端获得锁，把lock.youzhi的键值设置为时间值表示该键已被锁定，该客户端最后可以通过DEL lock.foo来释放该锁。如返回0，表明该锁已被其他客户端取得，这时我们可以先返回或进行重试等对方完成或等待锁超时。

3.时间戳

由于上面举的例子，要求key的操作需要顺序执行，所以需要保存一个时间戳判断set顺序。

```java
系统A key 1 {ValueA 7:00}
系统B key 1 { ValueB 7:05}
```
假设系统B先抢到锁，将key1设置为{ValueB 7:05}。接下来系统A抢到锁，发现自己的key1的时间戳早于缓存中的时间戳（7:00<7:05），那就不做set操作了。

4.什么是分布式锁

因为传统的加锁的做法（如java的synchronized和Lock）这里没用，只适合单点。因为这是分布式环境，需要的是分布式锁。当然，分布式锁可以基于很多种方式实现，比如zookeeper、redis等，不管哪种方式实现，基本原理是不变的：用一个状态值表示锁，对锁的占用和释放通过状态值来标识。


### 3.2、乐观锁

使用乐观锁的方式进行解决（成本较低，非阻塞，性能较高）。如何用乐观锁方式进行解决？

本质上是假设不会进行冲突，使用redis的命令watch进行构造条件。伪代码如下：
```
watch price

get price $price

$price = $price + 10

multi

set price $price

exec
```
解释一下：

watch这里表示监控该key值，后面的事务是有条件的执行，如果从watch的exec语句执行时，watch的key对应的value值被修改了，则事务不会执行。同样考虑刚刚的场景，

>T1时刻，连接1对price进行watch，读出price值为10，目标计算为20；

>T2时刻，连接2对price进行watch，读出price值为10，目标计算为20；

>T3时刻，连接2将目标值为20写到redis中，执行事务，事务返回成功。

>T4时刻，连接1也对price进行写操作，执行事务时，由于之前已经watch了price，price在T1至T4之间已经被修改过了，所以事务执行失败。

综上，该乐观锁机制可以简单明了的解决了写冲突的问题。

又问：如果多个写操作同时过来，100个写操作同时watch，则最终只会有一个成功，99个执行失败，何解？

如果同时进行有多个请求进行写操作，例如同一时刻有100个请求过来，那么只会有一个最终成功，其余99个全部会失败，效率不高。而且从业务层面，有些是不可接受的场景。例如：大家同时去抢一个红包，如果背后也是用乐观锁的机制去处理，那每个请求后都只有一个人成功打开红包，这对业务是不可忍受的。

在这种情况下，如果想让总体效率最大化，可以采用排队的机制进行。将所有需要对同一个key的请求进行入队操作，然后用一个消费者线程从队头依次读出请求，并对相应的key进行操作。这样对于同一个key的所有请求就都是顺序访问，正常逻辑下则不会有写失败的情况下产生 。从而最大化写逻辑的总体效率。

### 3.3、利用消息队列

在并发量过大的情况下,可以通过消息中间件进行处理,把并行读写进行串行化。把Redis.set操作放在队列中使其串行化,必须的一个一个执行。这种方式在一些高并发的场景中算是一种通用的解决方案。






