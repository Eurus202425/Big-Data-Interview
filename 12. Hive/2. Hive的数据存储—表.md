## Hive的数据存储——表

### 数据存储

1. 首先，Hive没有专门的数据存储格式，也没有为数据建立索引，用于可以非常自由的组织Hive中的表，只需要在创建表的时候告诉Hive数据中的列分隔符和行分隔符，这就可以解析数据了。

2. 其次，Hive中所有的数据都存储在HDFS中，Hive中包含4中数据模型：Tabel、ExternalTable、Partition、Bucket。

表是在数据库下面，而表里面又有分区、桶、倾斜的数据和正常的数据等；分区下面也是可以建立桶的。

###（1）Hive数据库

类似传统数据库的DataBase，在第三方数据库里实际是一张表。

简单示例命令行 hive > create database test_database;

###（2）内部表

Hive的内部表与数据库中的Table在概念上是类似。每一个Table在Hive中都有一个相应的目录存储数据，这个目录可以通过${HIVE_HOME}/conf/hive-site.xml配置文件中的hive.metastore.warehouse.dir属性来配置，这个属性默认的值是/user/hive/warehouse（这个目录在HDFS上），我们可以根据实际的情况来修改这个配置。如果我有一个表pvs，那么在HDFS中会创建/user/hive/warehouse/pvs目录（这里假定hive.metastore.warehouse.dir配置为/user/hive/warehouse）；pvs表所有的数据都存放在这个目录中。这个例外是外部表。所有的Table数据（不包括External Table）都保存在这个目录中。删除表时，元数据与数据都会被删除。

内部表简单示例：

创建数据文件：test_inner_table.txt

创建表：create table test_inner_table (key string)

加载数据：LOAD DATA LOCAL INPATH ‘filepath’ INTO TABLE test_inner_table

查看数据：select * from test_inner_table;  select count(*) from test_inner_table

删除表：drop table test_inner_table

###（3）外部表

外部表指向已经在HDFS中存在的数据，可以创建Partition。它和内部表在元数据的组织上是相同的，而实际数据的存储则有较大的差异。内部表的创建过程和数据加载过程这两个过程可以分别独立完成，也可以在同一个语句中完成，在加载数据的过程中，实际数据会被移动到数据仓库目录中；之后对数据对访问将会直接在数据仓库目录中完成。删除表时，表中的数据和元数据将会被同时删除。而外部表只有一个过程，加载数据和创建表同时完成（CREATE EXTERNAL TABLE ……LOCATION），实际数据是存储在LOCATION后面指定的 HDFS 路径中，并不会移动到数据仓库目录中。当删除一个External Table时，仅删除该链接。

外部表简单示例：

创建数据文件：test_external_table.txt

创建表：create external table test_external_table (key string)

加载数据：LOAD DATA INPATH ‘filepath’ INTO TABLE test_inner_table

查看数据：select * from test_external_table;  •select count(*) from test_external_table

删除表：drop table test_external_table

###（4）分区

Partition对应于数据库中的Partition列的密集索引，但是Hive中Partition的组织方式和数据库中的很不相同。在Hive中，表中的一个Partition对应于表下的一个目录，所有的Partition的数据都存储在对应的目录中。

例如pvs表中包含ds和city两个Partition，则对应于ds = 20090801, ctry = US 的HDFS子目录为/wh/pvs/ds=20090801/ctry=US；对应于 ds = 20090801, ctry = CA 的HDFS子目录为/wh/pvs/ds=20090801/ctry=CA。

分区表简单示例：

创建数据文件：test_partition_table.txt

创建表：create table test_partition_table (key string) partitioned by (dt string)

加载数据：LOAD DATA INPATH ‘filepath’ INTO TABLE test_partition_table partition (dt=‘2006’)

查看数据：select * from test_partition_table;  select count(*) from test_partition_table

删除表：drop table test_partition_table

###（5）桶

Buckets是将表的列通过Hash算法进一步分解成不同的文件存储。它对指定列计算hash，根据hash值切分数据，目的是为了并行，每一个Bucket对应一个文件。

例如将user列分散至32个bucket，首先对user列的值计算hash，对应hash值为0的HDFS目录为/wh/pvs/ds=20090801/ctry=US/part-00000；hash值为20的HDFS目录为/wh/pvs/ds=20090801/ctry=US/part-00020。如果想应用很多的Map任务这样是不错的选择。

对指定的列计算其hash，根据hash值切分数据，目的是为了并行，每一个桶对应一个文件（注意和分区的区别）。比如将wyp表id列分散至16个桶中，首先对id列的值计算hash，对应hash值为0和16的数据存储的HDFS目录为：/user/hive/warehouse/wyp/part-00000；而hash值为2的数据存储的HDFS 目录为：/user/hive/warehouse/wyp/part-00002。



###（6）Hive的视图

视图与传统数据库的视图类似。视图是只读的，它基于的基本表，如果改变，数据增加不会影响视图的呈现；如果删除，会出现问题。•如果不指定视图的列，会根据select语句后的生成。

示例：create view test_view as select * from test

